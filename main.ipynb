{"cells": [{"cell_type": "markdown", "metadata": {"toc-hr-collapsed": false}, "source": ["# MobileNetV2 \u2014 \u5783\u573e\u5206\u7c7b\n", "<br>\n", "<hr>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. \u5b9e\u9a8c\u7b80\u4ecb\n", "\n", "MindSpore\u662f\u6700\u4f73\u5339\u914dAscend\uff08\u6607\u817e\uff09\u82af\u7247\u7684\u5f00\u6e90AI\u8ba1\u7b97\u6846\u67b6\uff0c\u540c\u65f6\u4e5f\u652f\u6301CPU\u3001GPU\u5e73\u53f0\u3002\u8bbf\u95eeMindSpore\u5b98\u7f51\u4e86\u89e3\u66f4\u591a\uff1ahttps://www.mindspore.cn/\n", "\n", "\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u4e2d\uff0c\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u4e00\u4e2a\u5b9e\u7528\u7684\u6a21\u578b\u901a\u5e38\u975e\u5e38\u8017\u65f6\uff0c\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u80fd\u529b\u3002\u5e38\u7528\u7684\u6570\u636e\u5982OpenImage\u3001ImageNet\u3001VOC\u3001COCO\u7b49\u516c\u5f00\u5927\u578b\u6570\u636e\u96c6\uff0c\u89c4\u6a21\u8fbe\u5230\u51e0\u5341\u4e07\u751a\u81f3\u8d85\u8fc7\u4e0a\u767e\u4e07\u5f20\u3002\u7f51\u7edc\u548c\u5f00\u6e90\u793e\u533a\u4e0a\u901a\u5e38\u4f1a\u63d0\u4f9b\u8fd9\u4e9b\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u3002\u5927\u90e8\u5206\u7ec6\u5206\u9886\u57df\u4efb\u52a1\u5728\u8bad\u7ec3\u7f51\u7edc\u6a21\u578b\u65f6\uff0c\u5982\u679c\u4e0d\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u800c\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7f51\u7edc\uff0c\u4e0d\u4ec5\u8017\u65f6\uff0c\u4e14\u6a21\u578b\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6781\u5c0f\u503c\u548c\u8fc7\u62df\u5408\u3002\u56e0\u6b64\u5927\u90e8\u5206\u4efb\u52a1\u90fd\u4f1a\u9009\u62e9\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5728\u5176\u4e0a\u505a\u5fae\u8c03\uff08\u4e5f\u79f0\u4e3aFine-Tune\uff09\u3002\n", "\n", "\u672c\u5b9e\u9a8c\u4ee5MobileNetV2+\u5783\u573e\u5206\u7c7b\u6570\u636e\u96c6\u4e3a\u4f8b\uff0c\u4e3b\u8981\u4ecb\u7ecd\u5982\u5728\u4f7f\u7528MindSpore\u5728CPU/GPU\u5e73\u53f0\u4e0a\u8fdb\u884cFine-Tune\u3002\n", "\n", "\u5783\u573e\u5206\u7c7b\u4fe1\u606f\uff1a\n", "\n", "    {\n", "        '\u5e72\u5783\u573e': ['\u8d1d\u58f3', '\u6253\u706b\u673a', '\u65e7\u955c\u5b50', '\u626b\u628a', '\u9676\u74f7\u7897', '\u7259\u5237', '\u4e00\u6b21\u6027\u7b77\u5b50', '\u810f\u6c61\u8863\u670d'],\n", "        '\u53ef\u56de\u6536\u7269': ['\u62a5\u7eb8', '\u73bb\u7483\u5236\u54c1', '\u7bee\u7403', '\u5851\u6599\u74f6', '\u786c\u7eb8\u677f', '\u73bb\u7483\u74f6', '\u91d1\u5c5e\u5236\u54c1', '\u5e3d\u5b50', '\u6613\u62c9\u7f50', '\u7eb8\u5f20'],\n", "        '\u6e7f\u5783\u573e': ['\u83dc\u53f6', '\u6a59\u76ae', '\u86cb\u58f3', '\u9999\u8549\u76ae'],\n", "        '\u6709\u5bb3\u5783\u573e': ['\u7535\u6c60', '\u836f\u7247\u80f6\u56ca', '\u8367\u5149\u706f', '\u6cb9\u6f06\u6876']\n", "    }\n", "\n", "    ['\u8d1d\u58f3', '\u6253\u706b\u673a', '\u65e7\u955c\u5b50', '\u626b\u628a', '\u9676\u74f7\u7897', '\u7259\u5237', '\u4e00\u6b21\u6027\u7b77\u5b50', '\u810f\u6c61\u8863\u670d',\n", "    '\u62a5\u7eb8', '\u73bb\u7483\u5236\u54c1', '\u7bee\u7403', '\u5851\u6599\u74f6', '\u786c\u7eb8\u677f', '\u73bb\u7483\u74f6', '\u91d1\u5c5e\u5236\u54c1', '\u5e3d\u5b50', '\u6613\u62c9\u7f50', '\u7eb8\u5f20',\n", "    '\u83dc\u53f6', '\u6a59\u76ae', '\u86cb\u58f3', '\u9999\u8549\u76ae',\n", "    '\u7535\u6c60', '\u836f\u7247\u80f6\u56ca', '\u8367\u5149\u706f', '\u6cb9\u6f06\u6876']\n", "    \n", "    ['Seashell', 'Lighter', 'Old Mirror', 'Broom', 'Ceramic Bowl', 'Toothbrush', 'Disposable Chopsticks', 'Dirty Cloth',\n", "    'Newspaper', 'Glassware', 'Basketball', 'Plastic Bottle', 'Cardboard', 'Glass Bottle', 'Metalware', 'Hats', 'Cans', 'Paper',\n", "    'Vegetable Leaf', 'Orange Peel', 'Eggshell', 'Banana Peel',\n", "    'Battery', 'Tablet capsules', 'Fluorescent lamp', 'Paint bucket']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u811a\u672c\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u7684 Checkpoint \u548c\u6570\u636e\u96c6\u7ec4\u7ec7\u4e3a\u5982\u4e0b\u5f62\u5f0f\uff1a\n", "\n", "```bash\n", "\u251c\u2500\u2500 main.ipynb # \u5165\u53e3Jupyter Notebook\u6587\u4ef6\n", "\u2502\n", "\u251c\u2500\u2500 src_mindspore\n", "\u2502   \u251c\u2500\u2500 dataset.py\n", "\u2502   \u251c\u2500\u2500 mobilenetv2.py\n", "\u2502   \u2514\u2500\u2500 mobilenetv2-200_1067_gpu_cpu.ckpt\n", "\u2502\n", "\u251c\u2500\u2500 results/mobilenetv2.mindir # \u5f85\u751f\u6210\u7684MindSpore0.5.0\u6a21\u578b\u6587\u4ef6\n", "\u2502\n", "\u251c\u2500\u2500 train_main.py # \u5c06 main.ipynb Notebook \u8bad\u7ec3\u6a21\u578b\u4ee3\u7801\u8f6c\u5316\u4e3apy\u6587\u4ef6\n", "\u2502\n", "\u2514\u2500\u2500 datasets/5fbdf571c06d3433df85ac65-momodel/garbage_26x100/ # \u6570\u636e\u96c6\n", "    \u251c\u2500\u2500 train/\n", "    \u251c\u2500\u2500 val/\n", "    \u2514\u2500\u2500 label.txt\n", "\n", "\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u5bfc\u5165\u6807\u51c6\u5e93\u3001\u7b2c\u4e09\u65b9\u5e93\uff0c\u5df2\u53ca MindSpore \u7684\u6a21\u5757\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import math\n", "import numpy as np\n", "import os\n", "import cv2\n", "import random\n", "import shutil\n", "import time\n", "from matplotlib import pyplot as plt\n", "from easydict import EasyDict\n", "from PIL import Image\n", "\n", "import mindspore as ms\n", "from mindspore import context\n", "from mindspore import nn\n", "from mindspore import Tensor\n", "from mindspore.train.model import Model\n", "from mindspore.train.serialization import load_checkpoint, save_checkpoint, export\n", "from mindspore.train.callback import Callback, LossMonitor, ModelCheckpoint, CheckpointConfig\n", "\n", "from src_mindspore.dataset import create_dataset # \u6570\u636e\u5904\u7406\u811a\u672c\n", "from src_mindspore.mobilenetv2 import MobileNetV2Backbone, mobilenet_v2 # \u6a21\u578b\u5b9a\u4e49\u811a\u672c\n", "\n", "os.environ['GLOG_v'] = '2' # Log Level = Error\n", "has_gpu = (os.system('command -v nvidia-smi') == 0)\n", "print('Excuting with', 'GPU' if has_gpu else 'CPU', '.')\n", "context.set_context(mode=context.GRAPH_MODE, device_target='GPU' if has_gpu else 'CPU')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u914d\u7f6e\u540e\u7eed\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u63a8\u7406\u7528\u5230\u7684\u53c2\u6570\u3002\u53ef\u4ee5\u8c03\u6574\u4ee5\u4e0b\u8d85\u53c2\u4ee5\u63d0\u9ad8\u6a21\u578b\u8bad\u7ec3\u540e\u7684\u9a8c\u8bc1\u7cbe\u5ea6\uff1a\n", "\n", "- `epochs`\uff1a\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\u7684\u4ee3\u6570\uff1b\n", "- `lr_max`\uff1a\u5b66\u4e60\u7387\uff0c\u6216\u8005\u52a8\u6001\u5b66\u4e60\u7387\u7684\u6700\u5927\u503c\uff1b\n", "- `decay_type`\uff1a\u5b66\u4e60\u7387\u4e0b\u964d\u7b56\u7565\uff1b\n", "- `momentum`\uff1aMomentum\u4f18\u5316\u5668\u7684\u52a8\u91cf\u53c2\u6570\uff0c\u901a\u5e38\u4e3a0.9\uff1b\n", "- `weight_decay`\uff1a\u6b63\u5219\u5316\u9879\u7684\u7cfb\u6570\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u5783\u573e\u5206\u7c7b\u6570\u636e\u96c6\u6807\u7b7e\uff0c\u4ee5\u53ca\u7528\u4e8e\u6807\u7b7e\u6620\u5c04\u7684\u5b57\u5178\u3002\n", "index = {'00_00': 0, '00_01': 1, '00_02': 2, '00_03': 3, '00_04': 4, '00_05': 5, '00_06': 6, '00_07': 7,\n", "         '00_08': 8, '00_09': 9, '01_00': 10, '01_01': 11, '01_02': 12, '01_03': 13, '01_04': 14,\n", "         '01_05': 15, '01_06': 16, '01_07': 17, '02_00': 18, '02_01': 19, '02_02': 20, '02_03': 21,\n", "         '03_00': 22, '03_01': 23, '03_02': 24, '03_03': 25}\n", "inverted = {0: 'Plastic Bottle', 1: 'Hats', 2: 'Newspaper', 3: 'Cans', 4: 'Glassware', 5: 'Glass Bottle', 6: 'Cardboard', 7: 'Basketball',\n", "            8: 'Paper', 9: 'Metalware', 10: 'Disposable Chopsticks', 11: 'Lighter', 12: 'Broom', 13: 'Old Mirror', 14: 'Toothbrush',\n", "            15: 'Dirty Cloth', 16: 'Seashell', 17: 'Ceramic Bowl', 18: 'Paint bucket', 19: 'Battery', 20: 'Fluorescent lamp', 21: 'Tablet capsules',\n", "            22: 'Orange Peel', 23: 'Vegetable Leaf', 24: 'Eggshell', 25: 'Banana Peel'}\n", "\n", "# \u8bad\u7ec3\u8d85\u53c2\n", "config = EasyDict({\n", "    \"num_classes\": 26, # \u5206\u7c7b\u6570\uff0c\u5373\u8f93\u51fa\u5c42\u7684\u7ef4\u5ea6\n", "    \"reduction\": 'mean', # mean, max, Head\u90e8\u5206\u6c60\u5316\u91c7\u7528\u7684\u65b9\u5f0f\n", "    \"image_height\": 224,\n", "    \"image_width\": 224,\n", "    \"batch_size\": 24, # \u9274\u4e8eCPU\u5bb9\u5668\u6027\u80fd\uff0c\u592a\u5927\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u5361\u4f4f\n", "    \"eval_batch_size\": 10,\n", "    \"epochs\": 4, # \u8bf7\u5c1d\u8bd5\u4fee\u6539\u4ee5\u63d0\u5347\u7cbe\u5ea6\n", "    \"lr_max\": 0.01, # \u8bf7\u5c1d\u8bd5\u4fee\u6539\u4ee5\u63d0\u5347\u7cbe\u5ea6\n", "    \"decay_type\": 'constant', # \u8bf7\u5c1d\u8bd5\u4fee\u6539\u4ee5\u63d0\u5347\u7cbe\u5ea6\n", "    \"momentum\": 0.8, # \u8bf7\u5c1d\u8bd5\u4fee\u6539\u4ee5\u63d0\u5347\u7cbe\u5ea6\n", "    \"weight_decay\": 3.0, # \u8bf7\u5c1d\u8bd5\u4fee\u6539\u4ee5\u63d0\u5347\u7cbe\u5ea6\n", "    \"dataset_path\": \"./datasets/5fbdf571c06d3433df85ac65-momodel/garbage_26x100\",\n", "    \"features_path\": \"./results/garbage_26x100_features\", # \u4e34\u65f6\u76ee\u5f55\uff0c\u4fdd\u5b58\u51bb\u7ed3\u5c42Feature Map\uff0c\u53ef\u968f\u65f6\u5220\u9664\n", "    \"class_index\": index,\n", "    \"save_ckpt_epochs\": 1,\n", "    \"save_ckpt_path\": './results/ckpt_mobilenetv2',\n", "    \"pretrained_ckpt\": './src_mindspore/mobilenetv2-200_1067_cpu_gpu.ckpt',\n", "    \"export_path\": './results/mobilenetv2.mindir'\n", "\n", "})\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u5c55\u793a\u90e8\u5206\u5904\u7406\u540e\u7684\u6570\u636e"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["result = []\n", "ds = create_dataset(config=config, training=False)\n", "data_iterator = ds.create_dict_iterator(output_numpy=True)\n", "for i, data in enumerate(data_iterator):\n", "    if i >= 4:  # \u53ea\u663e\u793a\u524d\u56db\u4e2a\u56fe\u50cf\n", "        break\n", "    images = data['image'][0]\n", "    labels = data['label'][0]\n", "\n", "    plt.subplot(2, 2, i + 1)\n", "    plt.imshow(np.transpose(images, (1, 2, 0)))  # \u786e\u4fdd\u7ef4\u5ea6\u6b63\u786e\n", "    plt.title('label: %s' % inverted[labels])\n", "    plt.xticks([])\n", "\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. \u8bad\u7ec3\u7b56\u7565\n", "\n", "\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u8bad\u7ec3\u65f6\u91c7\u7528\u9759\u6001\u5b66\u4e60\u7387\uff0c\u59820.01\u3002\u968f\u7740\u8bad\u7ec3\u6b65\u6570\u7684\u589e\u52a0\uff0c\u6a21\u578b\u9010\u6e10\u8d8b\u4e8e\u6536\u655b\uff0c\u5bf9\u6743\u91cd\u53c2\u6570\u7684\u66f4\u65b0\u5e45\u5ea6\u5e94\u8be5\u9010\u6e10\u964d\u4f4e\uff0c\u4ee5\u51cf\u5c0f\u6a21\u578b\u8bad\u7ec3\u540e\u671f\u7684\u6296\u52a8\u3002\u6240\u4ee5\uff0c\u6a21\u578b\u8bad\u7ec3\u65f6\u53ef\u4ee5\u91c7\u7528\u52a8\u6001\u4e0b\u964d\u7684\u5b66\u4e60\u7387\uff0c\u5e38\u89c1\u7684\u5b66\u4e60\u7387\u4e0b\u964d\u7b56\u7565\u6709\uff1a\n", "\n", "- polynomial decay/square decay;\n", "- cosine decay;\n", "- exponential decay;\n", "- stage decay.\n", "\n", "\u8fd9\u91cc\u5b9e\u73b0cosine decay\u548csquare decay\u4e0b\u964d\u7b56\u7565\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_lr(total_steps, lr_init=0.0, lr_end=0.0, lr_max=0.1, warmup_steps=0, decay_type='cosine'):\n", "    \"\"\"\n", "    Applies cosine decay to generate learning rate array.\n", "\n", "    Args:\n", "       total_steps(int): all steps in training.\n", "       lr_init(float): init learning rate.\n", "       lr_end(float): end learning rate\n", "       lr_max(float): max learning rate.\n", "       warmup_steps(int): all steps in warmup epochs.\n", "\n", "    Returns:\n", "       list, learning rate array.\n", "    \"\"\"\n", "    lr_init, lr_end, lr_max = float(lr_init), float(lr_end), float(lr_max)\n", "    decay_steps = total_steps - warmup_steps\n", "    lr_all_steps = []\n", "    inc_per_step = (lr_max - lr_init) / warmup_steps if warmup_steps else 0\n", "    for i in range(total_steps):\n", "        if i < warmup_steps:\n", "            lr = lr_init + inc_per_step * (i + 1)\n", "        else:\n", "            if decay_type == 'cosine':\n", "                cosine_decay = 0.5 * (1 + math.cos(math.pi * (i - warmup_steps) / decay_steps))\n", "                lr = (lr_max - lr_end) * cosine_decay + lr_end\n", "            elif decay_type == 'square':\n", "                frac = 1.0 - float(i - warmup_steps) / (total_steps - warmup_steps)\n", "                lr = (lr_max - lr_end) * (frac * frac) + lr_end\n", "            else:\n", "                lr = lr_max\n", "        lr_all_steps.append(lr)\n", "\n", "    return lr_all_steps\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u89c2\u5bdf\u4e0d\u540c\u5b66\u4e60\u7387\u4e0b\u964d\u7b56\u7565\u7684\u66f2\u7ebf\uff1a"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["steps = 5*93\n", "plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='constant'))\n", "plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='square'))\n", "plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='cosine'))\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. \u6a21\u578b\u8bad\u7ec3\n", "\n", "\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u6dfb\u52a0\u68c0\u67e5\u70b9\uff08Checkpoint\uff09\u7528\u4e8e\u4fdd\u5b58\u6a21\u578b\u7684\u53c2\u6570\uff0c\u4ee5\u4fbf\u8fdb\u884c\u63a8\u7406\u53ca\u4e2d\u65ad\u540e\u518d\u8bad\u7ec3\u4f7f\u7528\u3002\u4f7f\u7528\u573a\u666f\u5982\u4e0b\uff1a\n", "\n", "- \u8bad\u7ec3\u540e\u63a8\u7406\u573a\u666f\n", "    - \u6a21\u578b\u8bad\u7ec3\u5b8c\u6bd5\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u53c2\u6570\uff0c\u7528\u4e8e\u63a8\u7406\u6216\u9884\u6d4b\u64cd\u4f5c\u3002\n", "    - \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u5b9e\u65f6\u9a8c\u8bc1\u7cbe\u5ea6\uff0c\u628a\u7cbe\u5ea6\u6700\u9ad8\u7684\u6a21\u578b\u53c2\u6570\u4fdd\u5b58\u4e0b\u6765\uff0c\u7528\u4e8e\u9884\u6d4b\u64cd\u4f5c\u3002\n", "- \u518d\u8bad\u7ec3\u573a\u666f\n", "    - \u8fdb\u884c\u957f\u65f6\u95f4\u8bad\u7ec3\u4efb\u52a1\u65f6\uff0c\u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684Checkpoint\u6587\u4ef6\uff0c\u9632\u6b62\u4efb\u52a1\u5f02\u5e38\u9000\u51fa\u540e\u4ece\u521d\u59cb\u72b6\u6001\u5f00\u59cb\u8bad\u7ec3\u3002\n", "    - Fine-tuning\uff08\u5fae\u8c03\uff09\u573a\u666f\uff0c\u5373\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u5e76\u4fdd\u5b58\u53c2\u6570\uff0c\u57fa\u4e8e\u8be5\u6a21\u578b\uff0c\u9762\u5411\u7b2c\u4e8c\u4e2a\u7c7b\u4f3c\u4efb\u52a1\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002\n", "\n", "\u8fd9\u91cc\u52a0\u8f7dImageNet\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u7684MobileNetv2\u8fdb\u884cFine-tuning\uff0c\u5e76\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u5b58Checkpoint\u3002\u8bad\u7ec3\u6709\u4e24\u79cd\u65b9\u5f0f\uff1a\n", "- \u65b9\u5f0f\u4e00\uff1a\u51bb\u7ed3\u7f51\u7edc\u7684Backbone\uff0c\u53ea\u8bad\u7ec3\u4fee\u6539\u7684FC\u5c42\uff08Head\uff09\u3002\u5176\u4e2d\uff0cBackbone\u518d\u5168\u91cf\u6570\u636e\u96c6\u4e0a\u505a\u4e00\u904d\u63a8\u7406\uff0c\u5f97\u5230Feature Map\uff0c\u5c06Feature Map\u4f5c\u4e3a\u8bad\u7ec3Head\u7684\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u6781\u5927\u8282\u7701\u8bad\u7ec3\u65f6\u95f4\u3002\n", "- \u65b9\u5f0f\u4e8c\uff1a\u5148\u51bb\u7ed3\u7f51\u7edc\u7684Backbone\uff0c\u53ea\u8bad\u7ec3\u7f51\u7edcHead\uff1b\u518d\u5bf9Backbone+Head\u505a\u6574\u7f51\u505a\u5fae\u8c03\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3.1 \u63d0\u53d6\u7279\u5f81\u96c6\n", "\n", "\u5c06\u51bb\u7ed3\u5c42\u5728\u5168\u91cf\u8bad\u7ec3\u96c6\u4e0a\u505a\u4e00\u904d\u63a8\u7406\uff0c\u7136\u540e\u4fdd\u5b58FeatureMap\uff0c\u4f5c\u4e3a\u4fee\u6539\u5c42\u7684\u6570\u636e\u96c6\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_features(net, dataset_path, config):\n", "    if not os.path.exists(config.features_path):\n", "        os.makedirs(config.features_path)\n", "    dataset = create_dataset(config=config)\n", "    step_size = dataset.get_dataset_size()\n", "    if step_size == 0:\n", "        raise ValueError(\"The step_size of dataset is zero. Check if the images count of train dataset is more \\\n", "            than batch_size in config.py\")\n", "\n", "    data_iter = dataset.create_dict_iterator()\n", "    for i, data in enumerate(data_iter):\n", "        features_path = os.path.join(config.features_path, f\"feature_{i}.npy\")\n", "        label_path = os.path.join(config.features_path, f\"label_{i}.npy\")\n", "        if not os.path.exists(features_path) or not os.path.exists(label_path):\n", "            image = data[\"image\"]\n", "            label = data[\"label\"]\n", "            features = net(image)\n", "            np.save(features_path, features.asnumpy())\n", "            np.save(label_path, label.asnumpy())\n", "        print(f\"Complete the batch {i+1}/{step_size}\")\n", "    return\n", "\n", "backbone = MobileNetV2Backbone()\n", "load_checkpoint(config.pretrained_ckpt, net=backbone)\n", "extract_features(backbone, config.dataset_path, config)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3.2 \u8bad\u7ec3 Head \u5c42\n", "\n", "\u81ea\u5b9a\u4e49Head\u5c42\uff0cCPU/GPU\u4e0a\u7b97\u5b50\u652f\u6301\u60c5\u51b5\u8bf7\u53c2\u8003\uff1ahttps://www.mindspore.cn/doc/note/zh-CN/r1.0/operator_list_ms.html"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class GlobalPooling(nn.Cell):\n", "    \"\"\"\n", "    Global avg pooling definition.\n", "\n", "    Args:\n", "        reduction: mean or max, which means AvgPooling or MaxpPooling.\n", "\n", "    Returns:\n", "        Tensor, output tensor.\n", "\n", "    Examples:\n", "        >>> GlobalAvgPooling()\n", "    \"\"\"\n", "\n", "    def __init__(self, reduction='mean'):\n", "        super(GlobalPooling, self).__init__()\n", "        if reduction == 'max':\n", "            self.mean = ms.ops.ReduceMax(keep_dims=False)\n", "        else:\n", "            self.mean = ms.ops.ReduceMean(keep_dims=False)\n", "\n", "    def construct(self, x):\n", "        x = self.mean(x, (2, 3))\n", "        return x\n", "\n", "\n", "class MobileNetV2Head(nn.Cell):\n", "    \"\"\"\n", "    MobileNetV2Head architecture.\n", "\n", "    Args:\n", "        input_channel (int): Number of channels of input.\n", "        hw (int): Height and width of input, 7 for MobileNetV2Backbone with image(224, 224).\n", "        num_classes (int): Number of classes. Default is 1000.\n", "        reduction: mean or max, which means AvgPooling or MaxpPooling.\n", "        activation: Activation function for output logits.\n", "    Returns:\n", "        Tensor, output tensor.\n", "\n", "    Examples:\n", "        >>> MobileNetV2Head(num_classes=1000)\n", "    \"\"\"\n", "\n", "    def __init__(self, input_channel=1280, hw=7, num_classes=1000, reduction='mean', activation=\"None\"):\n", "        super(MobileNetV2Head, self).__init__()\n", "        self.need_activation = True\n", "        if reduction:\n", "            self.flatten = GlobalPooling(reduction)\n", "        else:\n", "            self.flatten = nn.Flatten()\n", "            input_channel = input_channel * hw * hw\n", "        self.dense = nn.Dense(input_channel, num_classes, weight_init='ones', has_bias=False)\n", "        if activation == \"Sigmoid\":\n", "            self.activation = nn.Sigmoid()\n", "        elif activation == \"Softmax\":\n", "            self.activation = nn.Softmax()\n", "        else:\n", "            self.need_activation = False\n", "\n", "    def construct(self, x):\n", "        x = self.flatten(x)\n", "        x = self.dense(x)\n", "        if self.need_activation:\n", "            x = self.activation(x)\n", "        return x\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u5728\u63d0\u53d6\u7684\u7279\u5f81\u96c6\u4e0a\u8bad\u7ec3Head\u5c42\uff0c\u5373\u4fee\u6539\u5c42\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_head():\n", "    train_dataset = create_dataset(config=config)\n", "    eval_dataset = create_dataset(config=config)\n", "    step_size = train_dataset.get_dataset_size()\n", "\n", "    backbone = MobileNetV2Backbone()\n", "    # Freeze parameters of backbone. You can comment these two lines.\n", "    for param in backbone.get_parameters():\n", "        param.requires_grad = False\n", "    load_checkpoint(config.pretrained_ckpt, net=backbone)\n", "\n", "    head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)\n", "    network = mobilenet_v2(backbone, head)\n", "\n", "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n", "    lrs = build_lr(config.epochs * step_size, lr_max=config.lr_max, warmup_steps=0, decay_type=config.decay_type)\n", "    opt = nn.Momentum(head.trainable_params(), lrs, config.momentum, config.weight_decay)\n", "    net = nn.WithLossCell(head, loss)\n", "    train_step = nn.TrainOneStepCell(net, opt)\n", "    train_step.set_train()\n", "\n", "    # train\n", "    history = list()\n", "    features_path = config.features_path\n", "    idx_list = list(range(step_size))\n", "    for epoch in range(config.epochs):\n", "        random.shuffle(idx_list)\n", "        epoch_start = time.time()\n", "        losses = []\n", "        for j in idx_list:\n", "            feature = Tensor(np.load(os.path.join(features_path, f\"feature_{j}.npy\")))\n", "            label = Tensor(np.load(os.path.join(features_path, f\"label_{j}.npy\")))\n", "            losses.append(train_step(feature, label).asnumpy())\n", "        epoch_seconds = (time.time() - epoch_start)\n", "        epoch_loss = np.mean(np.array(losses))\n", "\n", "        history.append(epoch_loss)\n", "        print(\"epoch: {}, time cost: {}, avg loss: {}\".format(epoch + 1, epoch_seconds, epoch_loss))\n", "        if (epoch + 1) % config.save_ckpt_epochs == 0:\n", "            save_checkpoint(network, os.path.join(config.save_ckpt_path, f\"mobilenetv2-{epoch+1}.ckpt\"))\n", "\n", "    # evaluate\n", "    print('validating the model...')\n", "    eval_model = Model(network, loss, metrics={'acc', 'loss'})\n", "    acc = eval_model.eval(eval_dataset, dataset_sink_mode=False)\n", "    print(acc)\n", "\n", "    return history\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u7531\u4e8eMobileNetV2\u7f51\u7edc\u8f83\u5927\uff0c\u9a8c\u8bc1\uff08validate\uff09\u6a21\u578b\u65f6\u6267\u884c\u7684\u662f\u6574\u7f51\uff0c\u6574\u7f51\u5728CPU\u5e73\u53f0\u4e0a\u6267\u884c\u8f83\u6162\uff0c\u5982\u9047\u5361\u4f4f\u6216\u8005\u9a8c\u8bc1\u8fc7\u7a0b\u4e2dNotebook\u4e2d\u65ad\uff0c\u8bf7\u91cd\u542fKernel\u540e\u91cd\u65b0\u6267\u884c\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if os.path.exists(config.save_ckpt_path):\n", "    shutil.rmtree(config.save_ckpt_path)\n", "os.makedirs(config.save_ckpt_path)\n", "\n", "history = train_head()\n", "\n", "plt.plot(history, label='train_loss')\n", "plt.legend()\n", "plt.show()\n", "\n", "CKPT = f'mobilenetv2-{config.epochs}.ckpt'\n", "print(\"Chosen checkpoint is\", CKPT)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. \u6a21\u578b\u63a8\u7406\n", "\n", "\u52a0\u8f7d\u6a21\u578bCheckpoint\u8fdb\u884c\u63a8\u7406\u3002\n", "\n", "> \u4f7f\u7528load_checkpoint\u63a5\u53e3\u52a0\u8f7d\u6570\u636e\u65f6\uff0c\u9700\u8981\u628a\u6570\u636e\u4f20\u5165\u7ed9\u539f\u59cb\u7f51\u7edc\uff0c\u800c\u4e0d\u80fd\u4f20\u9012\u7ed9\u5e26\u6709\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\u7684\u8bad\u7ec3\u7f51\u7edc\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def image_process(image):\n", "    \"\"\"Precess one image per time.\n", "\n", "    Args:\n", "        image: shape (H, W, C)\n", "    \"\"\"\n", "    mean=[0.485*255, 0.456*255, 0.406*255]\n", "    std=[0.229*255, 0.224*255, 0.225*255]\n", "    image = (np.array(image) - mean) / std\n", "    image = image.transpose((2,0,1))\n", "    img_tensor = Tensor(np.array([image], np.float32))\n", "    return img_tensor\n", "\n", "def infer_one(network, image_path):\n", "    image = Image.open(image_path).resize((config.image_height, config.image_width))\n", "    logits = network(image_process(image))\n", "    pred = np.argmax(logits.asnumpy(), axis=1)[0]\n", "    print(image_path, inverted[pred])\n", "    return pred\n", "\n", "def infer(images):\n", "    backbone = MobileNetV2Backbone()\n", "    head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)\n", "    network = mobilenet_v2(backbone, head)\n", "    print('\u52a0\u8f7d\u6a21\u578b\u8def\u5f84:',os.path.join(config.save_ckpt_path, CKPT))\n", "    load_checkpoint(os.path.join(config.save_ckpt_path, CKPT), net=network)\n", "    for img in images:\n", "        infer_one(network, img)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_images = list()\n", "folder = os.path.join(config.dataset_path, 'val/00_01') # Hats\n", "for img in os.listdir(folder):\n", "    test_images.append(os.path.join(folder, img))\n", "\n", "infer(test_images)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. \u5bfc\u51fa MindIR \u6a21\u578b\u6587\u4ef6\n", "\n", "\u5f53\u6709\u4e86 CheckPoint \u6587\u4ef6\u540e\uff0c\u5982\u679c\u60f3\u7ee7\u7eed\u57fa\u4e8e MindSpore Lite \u5728\u624b\u673a\u7aef\u505a\u63a8\u7406\uff0c\u9700\u8981\u901a\u8fc7\u7f51\u7edc\u548c Checkpoint \u751f\u6210\u5bf9\u5e94\u7684 MindIR \u683c\u5f0f\u6a21\u578b\u6587\u4ef6\u3002\u5f53\u524d\u652f\u6301\u57fa\u4e8e\u9759\u6001\u56fe\uff0c\u4e14\u4e0d\u5305\u542b\u63a7\u5236\u6d41\u8bed\u4e49\u7684\u63a8\u7406\u7f51\u7edc\u5bfc\u51fa\u3002\u5bfc\u51fa\u8be5\u683c\u5f0f\u6587\u4ef6\u7684\u4ee3\u7801\u5982\u4e0b\uff1a"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from mindspore import export\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["backbone = MobileNetV2Backbone()\n", "# \u5bfc\u51fa\u5e26\u6709Softmax\u5c42\u7684\u6a21\u578b\n", "head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes,\n", "                       reduction=config.reduction, activation='Softmax')\n", "network = mobilenet_v2(backbone, head)\n", "load_checkpoint(os.path.join(config.save_ckpt_path, CKPT), net=network)\n", "\n", "input = np.random.uniform(0.0, 1.0, size=[1, 3, 224, 224]).astype(np.float32)\n", "export(network, Tensor(input), file_name=config.export_path, file_format='MINDIR')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. \u4f5c\u4e1a\u8bc4\u5206\n", "\n", "**\u6ce8\u610f\uff1a**\n", "\n", "\u901a\u8fc7\u5bf9\u4ee5\u4e0a\u6b65\u9aa4\u6d41\u7a0b\u7684\u4e86\u89e3\uff0c\u76f8\u4fe1\u5927\u5bb6\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6709\u4e86\u6df1\u523b\u7684\u8ba4\u8bc6\uff0c\u4f46\u662f\u6a21\u578b\u6bd4\u8f83\u7b80\u5355\uff0c\u51c6\u786e\u7387\u4e5f\u4e0d\u9ad8\uff0c\u5927\u5bb6\u53ef\u4ee5\u8bd5\u7740\u5199\u81ea\u5df1\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u8c03\u5230\u6700\u4f73\u72b6\u6001\u3002          \n", "1. \u4f60\u53ef\u4ee5\u5728\u6211\u4eec\u51c6\u597d\u7684\u63a5\u53e3\u4e2d\u5b9e\u73b0\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u82e5\u4f7f\u7528\u53ef\u4ee5\u4fee\u6539\u51fd\u6570\u63a5\u53e3\uff09\uff0c\u4e5f\u53ef\u4ee5\u81ea\u5df1\u5b9e\u73b0\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5199\u597d\u4ee3\u7801\u540e\u53ef\u4ee5\u5728 Py \u6587\u4ef6\u4e2d\u4f7f\u7528 GPU \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002\n", "2. \u5728\u8bad\u7ec3\u6a21\u578b\u7b49\u8fc7\u7a0b\u4e2d\u5982\u679c\u9700\u8981**\u4fdd\u5b58\u6570\u636e\u3001\u6a21\u578b**\u7b49\u8bf7\u5199\u5230 **results** \u6587\u4ef6\u5939\uff0c\u5982\u679c\u91c7\u7528 [\u79bb\u7ebf\u4efb\u52a1](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) \u8bf7\u52a1\u5fc5\u5c06\u6a21\u578b\u4fdd\u5b58\u5728 **results** \u6587\u4ef6\u5939\u4e0b\u3002\n", "3. \u8bad\u7ec3\u51fa\u81ea\u5df1\u6700\u597d\u7684\u6a21\u578b\u540e\uff0c\u5148\u6309\u7167\u4e0b\u5217 cell \u64cd\u4f5c\u65b9\u5f0f\u5b9e\u73b0 NoteBook \u52a0\u8f7d\u6a21\u578b\u6d4b\u8bd5\uff1b\u8bf7\u6d4b\u8bd5\u901a\u8fc7\u5728\u8fdb\u884c\u3010\u7cfb\u7edf\u6d4b\u8bd5\u3011\u3002\n", "4. \u70b9\u51fb\u5de6\u4fa7\u680f`\u63d0\u4ea4\u4f5c\u4e1a`\u540e\u70b9\u51fb`\u751f\u6210\u6587\u4ef6`\u5219\u53ea\u9700\u52fe\u9009 `predict()` \u51fd\u6570\u7684cell\uff0c\u5373\u3010**\u6a21\u578b\u9884\u6d4b\u4ee3\u7801\u7b54\u9898\u533a\u57df**\u3011\u7684 cell\u3002\n", "5. \u8bf7\u5bfc\u5165\u5fc5\u8981\u7684\u5305\u548c\u7b2c\u4e09\u65b9\u5e93 (\u5305\u62ec\u6b64\u6587\u4ef6\u4e2d\u66fe\u7ecf\u5bfc\u5165\u8fc7\u7684)\u3002\n", "6. \u8bf7\u52a0\u8f7d\u4f60\u8ba4\u4e3a\u8bad\u7ec3\u6700\u4f73\u7684\u6a21\u578b\uff0c\u5373\u8bf7\u6309\u8981\u6c42\u586b\u5199\u6a21\u578b\u8def\u5f84\u3002\n", "7. `predict()`\u51fd\u6570\u7684\u8f93\u5165\u548c\u8f93\u51fa\u8bf7\u4e0d\u8981\u6539\u52a8\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===========================================  **\u6a21\u578b\u9884\u6d4b\u4ee3\u7801\u7b54\u9898\u533a\u57df**  ===========================================  \n", "\u5728\u4e0b\u65b9\u7684\u4ee3\u7801\u5757\u4e2d\u7f16\u5199 **\u6a21\u578b\u9884\u6d4b** \u90e8\u5206\u7684\u4ee3\u7801\uff0c\u8bf7\u52ff\u5728\u522b\u7684\u4f4d\u7f6e\u4f5c\u7b54"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## \u751f\u6210 main.py \u65f6\u8bf7\u52fe\u9009\u6b64 cell\n", "# \u672c\u793a\u8303\u4ee5 NoteBook \u8bad\u7ec3\u6a21\u578b\u901a\u8fc7\u5e73\u53f0\u6d4b\u8bd5\u4e3a\u4f8b\uff1a\n", "\n", "# 1. \u5bfc\u5165\u76f8\u5173\u5305\n", "import os\n", "import cv2\n", "import numpy as np\n", "import mindspore as ms\n", "from mindspore import nn\n", "from mindspore import Tensor\n", "from easydict import EasyDict\n", "from mindspore import context\n", "from mindspore.train.serialization import load_checkpoint\n", "from src_mindspore.mobilenetv2 import MobileNetV2Backbone, mobilenet_v2  # \u6a21\u578b\u5b9a\u4e49\u811a\u672c\n", "\n", "os.environ['GLOG_v'] = '2'  # Log Level = Error\n", "has_gpu = (os.system('command -v nvidia-smi') == 0)\n", "print('Excuting with', 'GPU' if has_gpu else 'CPU', '.')\n", "context.set_context(mode=context.GRAPH_MODE, device_target='GPU' if has_gpu else 'CPU')\n", "\n", "# 2.\u7cfb\u7edf\u6d4b\u8bd5\u90e8\u5206\u6807\u7b7e\u4e0e\u8be5\u5904\u4e00\u81f4\uff0c\u8bf7\u4e0d\u8981\u6539\u52a8\n", "# \u5783\u573e\u5206\u7c7b\u6570\u636e\u96c6\u6807\u7b7e\uff0c\u4ee5\u53ca\u7528\u4e8e\u6807\u7b7e\u6620\u5c04\u7684\u5b57\u5178\u3002\n", "index = {'00_00': 0, '00_01': 1, '00_02': 2, '00_03': 3, '00_04': 4, '00_05': 5, '00_06': 6, '00_07': 7,\n", "         '00_08': 8, '00_09': 9, '01_00': 10, '01_01': 11, '01_02': 12, '01_03': 13, '01_04': 14,\n", "         '01_05': 15, '01_06': 16, '01_07': 17, '02_00': 18, '02_01': 19, '02_02': 20, '02_03': 21,\n", "         '03_00': 22, '03_01': 23, '03_02': 24, '03_03': 25}\n", "inverted = {0: 'Plastic Bottle', 1: 'Hats', 2: 'Newspaper', 3: 'Cans', 4: 'Glassware', 5: 'Glass Bottle', 6: 'Cardboard', 7: 'Basketball',\n", "            8: 'Paper', 9: 'Metalware', 10: 'Disposable Chopsticks', 11: 'Lighter', 12: 'Broom', 13: 'Old Mirror', 14: 'Toothbrush',\n", "            15: 'Dirty Cloth', 16: 'Seashell', 17: 'Ceramic Bowl', 18: 'Paint bucket', 19: 'Battery', 20: 'Fluorescent lamp', 21: 'Tablet capsules',\n", "            22: 'Orange Peel', 23: 'Vegetable Leaf', 24: 'Eggshell', 25: 'Banana Peel'}\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## \u751f\u6210 main.py \u65f6\u8bf7\u52fe\u9009\u6b64 cell\n", "\n", "# 3. NoteBook \u6a21\u578b\u8c03\u6574\u53c2\u6570\u90e8\u5206\uff0c\u4f60\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u6a21\u578b\u9700\u6c42\u4fee\u6539\u3001\u589e\u52a0\u3001\u5220\u9664\u3001\u5b8c\u5584\u90e8\u5206\u8d85\u53c2\u6570\n", "# \u8bad\u7ec3\u8d85\u53c2\n", "config = EasyDict({\n", "    \"num_classes\": 26,\n", "    \"reduction\": 'mean',\n", "    \"image_height\": 224,\n", "    \"image_width\": 224,\n", "    \"eval_batch_size\": 10\n", "})\n", "\n", "# 4. \u81ea\u5b9a\u4e49\u6a21\u578bHead\u90e8\u5206\n", "class GlobalPooling(nn.Cell):\n", "    def __init__(self, reduction='mean'):\n", "        super(GlobalPooling, self).__init__()\n", "        if reduction == 'max':\n", "            self.mean = ms.ops.ReduceMax(keep_dims=False)\n", "        else:\n", "            self.mean = ms.ops.ReduceMean(keep_dims=False)\n", "\n", "    def construct(self, x):\n", "        x = self.mean(x, (2, 3))\n", "        return x\n", "\n", "\n", "class MobileNetV2Head(nn.Cell):\n", "    def __init__(self, input_channel=1280, hw=7, num_classes=1000, reduction='mean', activation=\"None\"):\n", "        super(MobileNetV2Head, self).__init__()\n", "        if reduction:\n", "            self.flatten = GlobalPooling(reduction)\n", "        else:\n", "            self.flatten = nn.Flatten()\n", "            input_channel = input_channel * hw * hw\n", "        self.dense = nn.Dense(input_channel, num_classes, weight_init='ones', has_bias=False)\n", "        if activation == \"Sigmoid\":\n", "            self.activation = nn.Sigmoid()\n", "        elif activation == \"Softmax\":\n", "            self.activation = nn.Softmax()\n", "        else:\n", "            self.need_activation = False\n", "\n", "    def construct(self, x):\n", "        x = self.flatten(x)\n", "        x = self.dense(x)\n", "        if self.need_activation:\n", "            x = self.activation(x)\n", "        return x\n", "\n", "\n", "# -------------------------- 5.\u8bf7\u52a0\u8f7d\u60a8\u6700\u6ee1\u610f\u7684\u6a21\u578b ---------------------------\n", "# \u9996\u5148\u52a0\u8f7d\u7f51\u7edc\u6a21\u578b\n", "backbone = MobileNetV2Backbone()\n", "head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)\n", "network = mobilenet_v2(backbone, head)\n", "\n", "# \u52a0\u8f7d\u6a21\u578b,\u52a0\u8f7d\u8bf7\u6ce8\u610f model_path \u662f\u76f8\u5bf9\u8def\u5f84, \u4e0e\u5f53\u524d\u6587\u4ef6\u540c\u7ea7\u3002\n", "# \u5982\u679c\u4f60\u7684\u6a21\u578b\u662f\u5728 results \u6587\u4ef6\u5939\u4e0b\u7684\u6a21\u578b\uff0c\u5219 model_path = './results/ckpt_mobilenetv2/mobilenetv2-4.ckpt'\n", "\n", "model_path = './results/ckpt_mobilenetv2/mobilenetv2-4.ckpt'\n", "load_checkpoint(model_path, net=network)\n", "\n", "# ---------------------------------------------------------------------------\n", "\n", "def image_process(image):\n", "    \"\"\"Precess one image per time.\n", "\n", "    Args:\n", "        image: shape (H, W, C)\n", "    \"\"\"\n", "    mean=[0.485*255, 0.456*255, 0.406*255]\n", "    std=[0.229*255, 0.224*255, 0.225*255]\n", "    image = (np.array(image) - mean) / std\n", "    image = image.transpose((2,0,1))\n", "    img_tensor = Tensor(np.array([image], np.float32))\n", "    return img_tensor\n", "\n", "def predict(image):\n", "    \"\"\"\n", "    \u52a0\u8f7d\u6a21\u578b\u548c\u6a21\u578b\u9884\u6d4b\n", "    \u4e3b\u8981\u6b65\u9aa4:\n", "        1.\u56fe\u7247\u5904\u7406,\u6b64\u5904\u5c3d\u91cf\u4e0e\u8bad\u7ec3\u6a21\u578b\u6570\u636e\u5904\u7406\u4e00\u81f4\n", "        2.\u7528\u52a0\u8f7d\u7684\u6a21\u578b\u9884\u6d4b\u56fe\u7247\u7684\u7c7b\u522b\n", "    :param image: PIL \u8bfb\u53d6\u7684\u56fe\u7247\u5bf9\u8c61\uff0c\u6570\u636e\u7c7b\u578b\u662f np.array\uff0cshape (H, W, C)\n", "    :return: string, \u6a21\u578b\u8bc6\u522b\u56fe\u7247\u7684\u7c7b\u522b,\n", "            \u5305\u542b 'Plastic Bottle','Hats','Newspaper','Cans'\u7b49\u5171 26 \u4e2a\u7c7b\u522b\n", "    \"\"\"\n", "    # -------------------------- \u5b9e\u73b0\u56fe\u50cf\u5904\u7406\u90e8\u5206\u7684\u4ee3\u7801 ---------------------------\n", "    # \u8be5\u5904\u662f\u4e0e NoteBook \u8bad\u7ec3\u6570\u636e\u9884\u5904\u7406\u4e00\u81f4\uff1b\n", "    # \u5982\u4f7f\u7528\u5176\u5b83\u65b9\u5f0f\u8fdb\u884c\u6570\u636e\u5904\u7406\uff0c\u8bf7\u4fee\u6539\u5b8c\u5584\u8be5\u5904\uff0c\u5426\u5219\u5f71\u54cd\u6210\u7ee9\n", "    image = cv2.resize(image,(config.image_height, config.image_width))\n", "    image = image_process(image)\n", "\n", "    # -------------------------- \u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u90e8\u5206\u7684\u4ee3\u7801 ---------------------------\n", "    logits = network(image)\n", "    pred = np.argmax(logits.asnumpy(), axis=1)[0]\n", "\n", "    return inverted[pred]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u8f93\u5165\u56fe\u7247\u8def\u5f84\u548c\u540d\u79f0\n", "image_path = './datasets/5fbdf571c06d3433df85ac65-momodel/garbage_26x100/val/00_01/00037.jpg'\n", "\n", "# \u4f7f\u7528 Pillow \u8bfb\u53d6\u56fe\u7247\n", "image = np.array(Image.open(image_path))\n", "\n", "# \u6253\u5370\u8fd4\u56de\u7ed3\u679c\n", "print(predict(image_rgb))\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.5"}}, "nbformat": 4, "nbformat_minor": 4}